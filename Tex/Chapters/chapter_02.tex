%!TEX root = ../thesis.tex
\chapter{Аналіз та порівняння існуючих методів колоризації}
\label{chap:theory}

    \begin{figure}[h!]
        \centering
        \includegraphics[width=1\textwidth]{../Preps/StructureScheme.png}
        \caption{Структурна схема класифікації методів колоризації}
        \label{fig:StructureScheme}
    \end{figure}

    У цьому розділі проводиться більш детальний аналіз сучасних алгоритмів колоризації, що зображені на структурній схемі (рис. \ref{fig:StructureScheme}).
    Ми розглянемо еволюцію підходів від класичних оптимізаційних задач до новітніх генеративних моделей.

    Основна мета цього розділу — виявити сильні та слабкі сторони існуючих рішень за такими критеріями: точність відтворення кольорів, обчислювальна складність, можливість керування результатом та часова узгодженість для відеопослідовностей.

    На основі проведеного порівняльного аналізу буде обґрунтовано вибір базової архітектури для практичної реалізації системи.

\section{Алгоритмічні методи колоризації зображень}

    До епохи глибокого навчання колоризація розглядалася переважно як задача оптимізації.
    Класичні алгоритмічні методи можна розділити на дві великі групи: методи на основі втручання користувача (Scribble-based) та методи перенесення кольору зі зразку (Example-based).

    \subsection{Оптимізаційні методи (Scribble-based)}
        Цей підхід базується на припущенні, що сусідні пікселі з подібною інтенсивністю повинні мати подібний колір.
        Користувач наносить на чорно-біле зображення кольорові штрихи (scribbles), які слугують граничними умовами.
        Задача зводиться до мінімізації цільової функції енергії $J$ \cite{2020-survey, 2004-colorization-using-optimization}:

        $$ J(U) = \sum_{r} \left( U(r) - \sum_{s \in N(r)} w_{rs} U(s) \right)^2, $$

        де $ U(r)$ — колір у пікселі $r$, $N(r)$ — окіл пікселя, а $w_{rs}$ — ваговий коефіцієнт, що залежить від подібності яскравості пікселів $r$ та $s$.

        Перевагою методу є повний контроль користувача, проте він вимагає значних ручних зусиль і часто дає артефакти на межах об'єктів зі слабким контрастом.

    \subsection{Методи перенесення кольору (Example-based)}
        У цьому підході колір переноситься з референсного кольорового зображення на цільове чорно-біле шляхом зіставлення статистик яскравості та текстур.
        Ранні роботи використовували зіставлення гістограм у колірному просторі $l\alpha\beta$.
        Хоча цей метод є більш автоматизованим, він критично залежить від вдалого вибору референсного зображення та часто призводить до помилкового забарвлення семантично різних об'єктів, що мають схожу текстуру.

\section{Методи колоризації на основі нейронних мереж}

    Поява згорткових нейронних мереж (CNN) дозволила моделювати складні залежності між формою об'єкта та його ймовірним кольором, використовуючи великі набори даних (ImageNet, COCO).

    \subsection{Регресійні та класифікаційні підходи (CNN)}
        Перші нейромережеві методи намагалися прямо передбачити значення каналів $ab$ у просторі Lab, мінімізуючи середньоквадратичну помилку (MSE):
        $$ \mathcal{L}_{L2} = \frac{1}{2} \sum_{h,w} || Y_{gt} - \hat{Y} ||_2^2, $$
        де $Y_{gt}$ — справжнє зображення, а $\hat{Y}$ — згенероване.

        Проте, як зазначають Zhang et al. \cite{2016-colorful-image-colorization}, використання MSE призводить до усереднення всіх можливих кольорів, що дає ненасичені результати (''sepia effect'').

        Для вирішення цієї проблеми задачу було переформульовано як мультимодальну класифікацію, де мережа передбачає розподіл ймовірностей для квантованих відтінків кольору, що значно підвищило яскравість результатів.

    \subsection{Генеративно-змагальні мережі (GAN)}
        Мережі GAN, зокрема архітектура Pix2Pix \cite{2017-image-to-image-translation}, здійснили прорив у чіткості зображень.
        Генератор $G$ намагається створити реалістичне зображення, щоб обдурити дискримінатор $D$, який вчиться відрізняти справжні кольорові фото від згенерованих.
        Функція втрат GAN має вигляд:
        $$ \mathcal{L}_{cGAN}(G, D) = \mathbb{E}_{x, y}[\log D(x, y)] + \mathbb{E}_{x, z}[\log(1 - D(x, G(x, z)))]. $$
    
    Підходи на кшталт ChromaGAN \cite{2020-chromagan} інтегрують семантичну інформацію (клас об'єкта) у процес генерації, що дозволяє уникнути грубих помилок (наприклад, зелене небо).

    \subsection{Трансформери та механізми уваги}
        Останні дослідження \cite{2021-colorization-transformer, 2022-unicolor} показують, що згорткові мережі мають обмежене рецептивне поле і погано справляються з моделюванням глобальних зв'язків.
        Трансформери (Vision Transformers) використовують механізм Self-Attention для врахування контексту всього зображення, що є критично важливим для узгодженого забарвлення великих однорідних областей або складних сцен з багатьма об'єктами.
        Зокрема, модель Colorization Transformer розбиває зображення на послідовність патчів і генерує кольори авторегресійно або паралельно.

    \subsection{Дифузійні імовірнісні моделі (Diffusion Models)}
        Найсучаснішим класом моделей є DDPM (Denoising Diffusion Probabilistic Models).
        На відміну від GAN, які генерують зображення за один прохід, дифузійні моделі (наприклад, Palette \cite{2022-palette-image-to-image-diffusion-models}, DDColor \cite{2023-ddcolor}) формують зображення ітеративно, поступово видаляючи шум з випадкового сигналу під керуванням вхідного чорно-білого зображення.

        % [Image of diffusion model forward and reverse process diagram]

        Цей процес описується стохастичними диференціальними рівняннями.
        Перевагою дифузійних моделей є висока стабільність навчання (відсутність ''mode collapse'', типового для GAN) та неперевершена деталізація текстур.
        Недоліком є висока обчислювальна складність та повільний час інференсу.

\section{Особливості колоризації відео}

    Колоризація відео є значно складнішою задачею через необхідність забезпечення часової узгодженості.
    Незалежна покадрова обробка відео навіть найкращими моделями для зображень призводить до ефекту мерехтіння, оскільки нейромережа може обирати різні варіанти кольору для одного й того ж об'єкта в сусідніх кадрах через незначні зміни освітлення або шуму.

    Для розв'язання цієї проблеми використовуються наступні підходи:
    \begin{itemize}[label=$\bullet$]
        \item \textbf{Оптичний потік (Optical Flow):} Використання векторів руху для деформації (warping) кольорів з попереднього кадру $t-1$ на поточний кадр $t$.
            Це дозволяє ''переносити'' вже згенеровані кольори.
        \item \textbf{Глибоке поширення ознак (Deep Feature Propagation):} Замість перенесення пікселів, переносяться карти ознак у латентному просторі мережі \cite{2024-temporally-consistent-video-colorization}.
        \item \textbf{Саморегуляризація (Self-regularization):} Використання функції втрат, що штрафує мережу за різницю кольорів у відповідних точках сусідніх кадрів \cite{2019-fully-automatic-video-colorization-official}.
    \end{itemize}

    Сучасні моделі, такі як VanGogh \cite{2025-vangogh} та Stable Video Diffusion \cite{2023-stable-video-diffusion}, інтегрують часові модулі (Temporal Attention) безпосередньо в архітектуру дифузійної моделі, що дозволяє генерувати цілісні відеофрагменти, а не окремі кадри.

\section{Порівняння різних методів колоризації}
    Узагальнимо характеристики розглянутих методів у порівняльній таблиці \ref{tab:comparison}.
    Для аналізу обрано такі критерії:
    \begin{itemize}[label=$\bullet$]
        \item \textbf{Якість (Quality):} реалістичність та насиченість кольорів.
        \item \textbf{Узгодженість (Consistency):} відсутність артефактів та мерехтіння.
        \item \textbf{Керованість (Control):} можливість користувача впливати на результат.
        \item \textbf{Швидкість (Speed):} час обробки одного кадру.
    \end{itemize}

    \begin{table}[ht]
        \centering
        \caption{Порівняльний аналіз методів колоризації}
        \label{tab:comparison}
        \begin{tabular}{|p{0.2\textwidth}|p{0.2\textwidth}|p{0.25\textwidth}|p{0.25\textwidth}|}
            \hline
            \textbf{Метод / Архітектура} & \textbf{Представники} & \textbf{Переваги} & \textbf{Недоліки} \\
            \hline
            Класичні оптимізаційні & Levin et al.\cite{2004-colorization-using-optimization} & Повний контроль користувача, відсутність галюцинацій & Дуже повільні, вимагають ручної розмітки, погана робота зі складними текстурами \\
            \hline
            CNN & Zhang et al. \cite{2016-colorful-image-colorization}, Larsson \cite{2016-learning-representations-for-automatic-colorization} & Висока швидкість, стабільність & ''Ефект сепії'', низька варіативність, відсутність текстур \\
            \hline
            GAN & Pix2Pix \cite{2017-image-to-image-translation}, ChromaGAN \cite{2020-chromagan} & Висока чіткість, яскраві кольори & Нестабільність тренування, генерація артефактів, складність масштабування на відео \\
            \hline
            Transformers & ColTran \cite{2021-colorization-transformer}, UniColor \cite{2022-unicolor} & Врахування глобального контексту, мультимодальність & Високі вимоги до пам'яті \\
            \hline
            Diffusion Models & Palette \cite{2022-palette-image-to-image-diffusion-models}, DDColor \cite{2023-ddcolor} & SOTA якість, фотореалізм, відмінна керованість & багаторазові ітерації, високі вимоги до GPU \\
            \hline
        \end{tabular}
    \end{table}

    Як видно з таблиці, дифузійні моделі демонструють найкращу якість генерації, проте поступаються у швидкості методам на основі CNN та GAN.
    Для задачі колоризації відео критичним фактором є компроміс між якістю кожного окремого кадру та їх часовою узгодженістю.
    Гібридні підходи, що поєднують генеративну силу дифузії з механізмами поширення ознак, виглядають найбільш перспективними для подальшої розробки.

\chapconclude{\ref{chap:theory}}

    У другому розділі було проведено аналіз теоретичних засад та алгоритмічних реалізацій систем колоризації.
    Було встановлено, що класичні методи є застарілими для задач автоматичної обробки, оскільки вимагають значного втручання оператора.
    
    Порівняння нейромережевих підходів показало, що хоча GAN забезпечують швидкий інференс, вони часто страждають від нестабільності та артефактів.
    Дифузійні моделі на сьогоднішній день забезпечують найвищу якість зображення та найкращі можливості для інтерактивного керування, що є критичним для створення зручної системи.
    
    Для колоризації відео основною проблемою залишається часова неузгодженість.
    Тому в наступному розділі, присвяченому розробці власної системи, буде скоріше за все обрано підхід на основі дифузійної моделі з інтеграцією механізму Attention для забезпечення часової стабільності між кадрами.
    Це дозволить поєднати високу якість генерації текстур з плавністю відеопослідовності.

    % До другого розділу також краще написати малесенький вступ. Зокрема, це 
    % збільшує загальний об'єм роботи та покращує її читабельність.


    % У другому розділі необхідно наводити розв'язання поставленої перед вами 
    % задачі у теоретичному або аналітичному сенсі (хоча, звісно, все залежить 
    % від того, яка саме задача перед вами поставлена).

    % Бажано, щоб кожен пункт завдань, окреслених у вступі, відповідав певному 
    % розділу або підрозділу у дипломній роботі.

    % Посилання до роботи рекомендовано робити за допомогою підсистеми BibTex. 
    % Це максимально зручно, повірте мені. Усі притомні світові журнали надають 
    % посилання на свої статті у вигляді bib-файлів, з яких просто треба 
    % перенести відомості у свій файл. Існують інструменти автоматизованого створення bib-файлів, наприклад, JabRef.
    % Якщо у вас нема автоматизованого механізму, то посилання на джерела у 
    % bib-файлах легко створюються вручну. Головне --- не забувати чотири простих 
    % правила:

    % 1) Імена авторів необхідно подавати у вигляді <<Прізвище, Ім'я>> та 
    % розділяти ключовим словом <<and>>, наприклад:

    % \texttt{author = ''Яковлєв, Сергій Володимирович and Дамблдор, Альбус Персиваль Вульфрік Брайан''}

    % 2) Після усіх полів запису необхідно ставити кому, окрім останнього.

    % 3) Джерела у переліку посилань з'являться тільки після того, як ви зробите 
    % посилання на нього у тексті, наприклад, див. роботи~\cite{ct1, ct2}.

    % Наприкінці розділу знову наводяться коротенькі підсумки.