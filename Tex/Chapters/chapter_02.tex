%!TEX root = ../thesis.tex
\chapter{Аналіз та порівняння існуючих методів колоризації}
\label{chap:theory}

    \begin{figure}[h!]
        \centering
        \includegraphics[width=1\textwidth]{../Preps/СтруктурнаСхема.png}
        \caption{Структурна схема класифікації методів колоризації}
        \label{fig:classification_scheme}
    \end{figure}

    У цьому розділі проводиться детальний аналіз сучасних алгоритмів колоризації, що зображені на структурній схемі (рис. \ref{fig:classification_scheme}). Ми розглянемо еволюцію підходів від класичних оптимізаційних задач до новітніх генеративних моделей.
    Основна мета цього розділу — виявити сильні та слабкі сторони існуючих рішень за такими критеріями: точність відтворення кольорів, обчислювальна складність, можливість керування результатом та часова узгодженість для відеопослідовностей.
    На основі проведеного порівняльного аналізу буде обґрунтовано вибір базової архітектури для практичної реалізації системи.

\section{Алгоритмічні методи колоризації зображень}

    До епохи глибокого навчання (Deep Learning) колоризація розглядалася переважно як задача оптимізації. Класичні алгоритмічні методи можна розділити на дві великі групи: методи на основі втручання користувача (Scribble-based) та методи перенесення кольору з прикладу (Example-based).

    \subsection{Оптимізаційні методи (Scribble-based)}
    Цей підхід базується на припущенні, що сусідні пікселі з подібною інтенсивністю (яскравістю) повинні мати подібний колір. Користувач наносить на чорно-біле зображення кольорові штрихи (scribbles), які слугують граничними умовами.
    Задача зводиться до мінімізації цільової функції енергії $E$:
    
    $$ E(U) = \sum_{r} \left( U(r) - \sum_{s \in N(r)} w_{rs} U(s) \right)^2, $$
    
    де $U(r)$ — колір (хромінанс) у пікселі $r$, $N(r)$ — окіл пікселя, а $w_{rs}$ — ваговий коефіцієнт, що залежить від подібності яскравості пікселів $r$ та $s$.
    
    
    
    Перевагою методу є повний контроль користувача, проте він вимагає значних ручних зусиль і часто дає артефакти на межах об'єктів зі слабким контрастом.

    \subsection{Методи перенесення кольору (Example-based)}
    У цьому підході колір переноситься з референсного кольорового зображення на цільове чорно-біле шляхом зіставлення статистик яскравості та текстур. Ранні роботи використовували зіставлення гістограм у колірному просторі $l\alpha\beta$. Хоча цей метод є більш автоматизованим, він критично залежить від вдалого вибору референсного зображення та часто призводить до помилкового забарвлення семантично різних об'єктів, що мають схожу текстуру.

\section{Методи колоризації на основі нейронних мереж}

    Поява згорткових нейронних мереж (CNN) дозволила моделювати складні залежності між формою об'єкта та його ймовірним кольором, використовуючи великі набори даних (ImageNet, COCO).

    \subsection{Регресійні та класифікаційні підходи (CNN)}
    Перші нейромережеві методи намагалися прямо передбачити значення каналів $ab$ у просторі Lab, мінімізуючи середньоквадратичну помилку (MSE) або L2-loss:
    $$ \mathcal{L}_{L2} = \frac{1}{2} \sum_{h,w} || Y_{gt} - \hat{Y} ||_2^2, $$
    де $Y_{gt}$ — справжнє зображення, а $\hat{Y}$ — згенероване. Проте, як зазначають Zhang et al. \cite{2016-colorful-image-colorization}, використання L2-loss призводить до усереднення всіх можливих кольорів, що дає ненасичені, сіро-бурі результати ("sepia effect").
    Для вирішення цієї проблеми задачу було переформульовано як мультимодальну класифікацію, де мережа передбачає розподіл ймовірностей для квантованих відтінків кольору, що значно підвищило яскравість результатів.

    \subsection{Генеративно-змагальні мережі (GAN)}
    Мережі GAN, зокрема архітектура Pix2Pix \cite{2017-image-to-image-translation}, здійснили прорив у чіткості зображень. Генератор $G$ намагається створити реалістичне зображення, щоб обдурити дискримінатор $D$, який вчиться відрізняти справжні кольорові фото від згенерованих.
    Функція втрат GAN має вигляд:
    $$ \mathcal{L}_{cGAN}(G, D) = \mathbb{E}_{x, y}[\log D(x, y)] + \mathbb{E}_{x, z}[\log(1 - D(x, G(x, z)))]. $$
    
    
    
    Підходи на кшталт ChromaGAN \cite{2020-chromagan} інтегрують семантичну інформацію (клас об'єкта) у процес генерації, що дозволяє уникнути грубих помилок (наприклад, зелене небо).

    \subsection{Трансформери та механізми уваги}
    Останні дослідження \cite{2021, 2022-unicolor} показують, що згорткові мережі мають обмежене рецептивне поле і погано справляються з моделюванням глобальних зв'язків. Трансформери (Vision Transformers) використовують механізм Self-Attention для врахування контексту всього зображення, що є критично важливим для узгодженого забарвлення великих однорідних областей або складних сцен з багатьма об'єктами.
    Зокрема, модель Colorization Transformer розбиває зображення на послідовність патчів і генерує кольори авторегресійно або паралельно.

    \subsection{Дифузійні імовірнісні моделі (Diffusion Models)}
    Найсучаснішим класом моделей є DDPM (Denoising Diffusion Probabilistic Models). На відміну від GAN, які генерують зображення за один прохід, дифузійні моделі (наприклад, Palette \cite{2022-palette-image-to-image-diffusion-models}, DDColor \cite{2023-ddcolor}) формують зображення ітеративно, поступово видаляючи шум з випадкового сигналу під керуванням вхідного чорно-білого зображення.
    
    

[Image of diffusion model forward and reverse process diagram]

    
    Цей процес описується стохастичними диференціальними рівняннями. Перевагою дифузійних моделей є висока стабільність навчання (відсутність "mode collapse", типового для GAN) та неперевершена деталізація текстур. Недоліком є висока обчислювальна складність та повільний час інференсу.

\section{Особливості колоризації відео}

    Колоризація відео є значно складнішою задачею через необхідність забезпечення часової узгодженості (temporal consistency). Незалежна покадрова обробка відео навіть найкращими моделями для зображень призводить до ефекту мерехтіння (flickering), оскільки нейромережа може обирати різні варіанти кольору для одного й того ж об'єкта в сусідніх кадрах через незначні зміни освітлення або шуму.

    Для розв'язання цієї проблеми використовуються наступні підходи:
    \begin{itemize}
        \item \textbf{Оптичний потік (Optical Flow):} Використання векторів руху для деформації (warping) кольорів з попереднього кадру $t-1$ на поточний кадр $t$. Це дозволяє "переносити" вже згенеровані кольори.
        
        \item \textbf{Глибоке поширення ознак (Deep Feature Propagation):} Замість перенесення пікселів, переносяться карти ознак у латентному просторі мережі \cite{2024-temporally-consistent-video-colorization}.
        \item \textbf{Саморегуляризація (Self-regularization):} Використання функції втрат, що штрафує мережу за різницю кольорів у відповідних точках сусідніх кадрів \cite{2019-fully-automatic-video-colorization-official}.
    \end{itemize}

    Сучасні моделі, такі як VanGogh \cite{2025-vangogh} та Stable Video Diffusion \cite{2023-stable-video-diffusion}, інтегрують часові модулі (Temporal Attention) безпосередньо в архітектуру дифузійної моделі, що дозволяє генерувати цілісні відеофрагменти, а не окремі кадри.

\section{Порівняння різних методів колоризації}

    Узагальнимо характеристики розглянутих методів у порівняльній таблиці \ref{tab:comparison}. Для аналізу обрано такі критерії:
    \begin{itemize}
        \item \textbf{Якість (Quality):} реалістичність та насиченість кольорів.
        \item \textbf{Узгодженість (Consistency):} відсутність артефактів та мерехтіння (для відео).
        \item \textbf{Керованість (Control):} можливість користувача впливати на результат (текст, приклади).
        \item \textbf{Швидкість (Speed):} час обробки одного кадру.
    \end{itemize}

    \begin{table}[ht]
        \centering
        \caption{Порівняльний аналіз методів колоризації}
        \label{tab:comparison}
        \begin{tabular}{|p{0.2\textwidth}|p{0.2\textwidth}|p{0.25\textwidth}|p{0.25\textwidth}|}
        \hline
        \textbf{Метод / Архітектура} & \textbf{Представники} & \textbf{Переваги} & \textbf{Недоліки} \\ \hline
        
        Класичні оптимізаційні & Levin et al., Welsh et al. & Повний контроль користувача, відсутність галюцинацій & Дуже повільні, вимагають ручної розмітки, погана робота зі складними текстурами \\ \hline
        
        CNN (L2/Classif.) & Zhang et al. \cite{2016-colorful-image-colorization}, Larsson \cite{2016} & Висока швидкість, стабільність & "Ефект сепії" (L2), низька варіативність, відсутність текстур \\ \hline
        
        GAN (Adversarial) & Pix2Pix \cite{2017-image-to-image-translation}, ChromaGAN \cite{2020-chromagan} & Висока чіткість, яскраві кольори & Нестабільність тренування, генерація артефактів, складність масштабування на відео \\ \hline
        
        Transformers & ColTran \cite{2021}, UniColor \cite{2022-unicolor} & Врахування глобального контексту, мультимодальність & Високі вимоги до пам'яті (Quadratic attention complexity) \\ \hline
        
        Diffusion Models & Palette \cite{2022-palette-image-to-image-diffusion-models}, DDColor \cite{2023-ddcolor} & SOTA якість, фотореалізм, відмінна керованість & Повільний інференс (багаторазові ітерації), високі вимоги до GPU \\ \hline
        \end{tabular}
    \end{table}

    Як видно з таблиці, дифузійні моделі демонструють найкращу якість генерації, проте поступаються у швидкості методам на основі CNN та GAN. Для задачі колоризації відео критичним фактором є компроміс між якістю кожного окремого кадру (де лідирують Diffusion Models) та їх часовою узгодженістю. Гібридні підходи, що поєднують генеративну силу дифузії з механізмами поширення ознак (Feature Propagation), виглядають найбільш перспективними для подальшої розробки.

\chapconclude{\ref{chap:theory}}

    У другому розділі було проведено аналіз теоретичних засад та алгоритмічних реалізацій систем колоризації. Було встановлено, що класичні методи є морально застарілими для задач автоматичної обробки, оскільки вимагають значного втручання оператора.
    
    Порівняння нейромережевих підходів показало, що хоча GAN забезпечують швидкий інференс, вони часто страждають від нестабільності та артефактів. Дифузійні моделі (Diffusion Models) на сьогоднішній день забезпечують найвищу якість зображення та найкращі можливості для інтерактивного керування (через текст або приклади), що є критичним для створення зручної системи.
    
    Для колоризації відео основною проблемою залишається часова неузгодженість. Тому в наступному розділі, присвяченому розробці власної системи, буде обрано підхід на основі дифузійної моделі з інтеграцією механізму Attention для забезпечення часової стабільності між кадрами. Це дозволить поєднати високу якість генерації текстур з плавністю відеопослідовності.

% \chapter{Аналіз та порівняння існуючих методів колоризації}
% \label{chap:theory}

%     \begin{figure}[h!]
%         \centering
%         \includegraphics[width=1\textwidth]{../Preps/СтруктурнаСхема.png}
%         \caption{Структурна Схема}
%     \end{figure}

%     Розділ присвячено аналізу сучасних алгоритмів колоризації, включаючи класичні та нейромережеві підходи.
%     Тут проводиться порівняння методів за основними критеріями: точність відтворення кольорів, швидкість роботи, здатність до багатоваріантної генерації результатів та інтерактивність.
%     На основі цього аналізу обґрунтовується вибір алгоритмів для подальшої розробки системи.

%     % До другого розділу також краще написати малесенький вступ. Зокрема, це 
%     % збільшує загальний об'єм роботи та покращує її читабельність.

% \section{Алгоритмічні методи колоризації зображень}

%     % У другому розділі необхідно наводити розв'язання поставленої перед вами 
%     % задачі у теоретичному або аналітичному сенсі (хоча, звісно, все залежить 
%     % від того, яка саме задача перед вами поставлена).

% \section{Методи колоризації на основі нейронних мереж}

%     % Для подання матеріалів можна використовувати таблиці (наприклад, 
%     % Таблицю \ref{tab_weight}). Розмір шрифту у таблиці може бути меншим за 14~pt (наприклад, 12~pt, або навіть 10~pt, якщо так таблиця виглядає зрозуміліше та компактніше).

%     %     \begin{table}[ht]
%     %     \setfontsize{14pt}
%     %     \caption{Розрахунок якоїсь фантастичної дичини у декілька кроків}
%     %     \label{tab_weight}
%     %     \centering
%     %         \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
%     %         \hline \multirow{2}{*}{Параметр $x_i$} & \multicolumn{4}{c|}{Параметр $x_j$} & 
%     %             \multicolumn{2}{c|}{Перший крок} & \multicolumn{2}{c|}{Другий крок} \\
%     %         \cline{2-9} & $X_1$ & $X_2$ & $X_3$ & $X_4$ & $w_i$ & 
%     %             ${K_\text{в}}_i$ & $w_i$ & ${K_\text{в}}_i$ \\
%     %         \hline $X_1$ & 1 & 1 & 1.5 & 1.5 & 5 & 0.31 & 19 & 0.32 \\
%     %         \hline $X_2$ & 1 & 1 & 1.5 & 1.5 & 5 & 0.31 & 19 & 0.32 \\
%     %         \hline $X_3$ & 0.5 & 0.5 & 1 & 0.5 & 2.5 & 0.16 & 9.25 & 0.16 \\
%     %         \hline $X_4$ & 0.5 & 0.5 & 1.5 & 1 & 3.5 & 0.22 & 12.25 & 0.20 \\
%     %         \hline \multicolumn{5}{|c|}{Разом:} & 16 & 1 & 59.5 & 1 \\
%     %         \hline
%     %         \end{tabular}
%     %     \end{table}

%     % Бажано, щоб кожен пункт завдань, окреслених у вступі, відповідав певному 
%     % розділу або підрозділу у дипломній роботі.

%     % \begin{theorem}
%     % Нумерація у наступних розділах також проставляється автоматично та коректно.
%     % \end{theorem}

% \section{Особливості колоризації відео}

%     % Для подання матеріалів також дуже зручними є рисунки (наприклад, рисунки 
%     % \ref{fig_sudak} або \ref{fig_pacman}).


%     % \begin{figure}[ht]
%     % \centering
%     %     \begin{subfigure}[b]{0.5\textwidth}    
%     %         \includegraphics[scale=0.3]{Images/Sudak.png}
%     %         \caption{}
%     %         % обратите внимание на знак % после \end{subfigure} и 
%     %         % отсутствие пустых строк и разделителей после \end{subfigure}
%     %         % -- это сливает в одну строку подфигуры
%     %     \end{subfigure}%
%     %     \begin{subfigure}[b]{0.5\textwidth}
%     %         \includegraphics[scale=0.3]{Images/Tudak.png}
%     %         \caption{}
%     %     \end{subfigure}
    
%     %     \caption{Різні види риб: (a) судак, (б) тудак.}
%     %     \label{fig_sudak}
%     % \end{figure}

%     % \begin{figure}[ht]
%     %         \centering
%     %         \includegraphics[scale=0.5]{Images/Pacman.jpg}
%     %         \caption{Частка кругових діаграм, які схожі на Пекмена}
%     %         \label{fig_pacman}
%     % \end{figure}

% \section{Порівняння різних методів колоризації}

%     % Посилання до роботи рекомендовано робити за допомогою підсистеми BibTex. 
%     % Це максимально зручно, повірте мені. Усі притомні світові журнали надають 
%     % посилання на свої статті у вигляді bib-файлів, з яких просто треба 
%     % перенести відомості у свій файл. Існують інструменти автоматизованого створення bib-файлів, наприклад, JabRef.
%     % Якщо у вас нема автоматизованого механізму, то посилання на джерела у 
%     % bib-файлах легко створюються вручну. Головне --- не забувати чотири простих 
%     % правила:

%     % 1) Імена авторів необхідно подавати у вигляді <<Прізвище, Ім'я>> та 
%     % розділяти ключовим словом <<and>>, наприклад:

%     % \texttt{author = "Яковлєв, Сергій Володимирович and Дамблдор, Альбус Персиваль Вульфрік Брайан"}

%     % 2) Після усіх полів запису необхідно ставити кому, окрім останнього.

%     % 3) Джерела у переліку посилань з'являться тільки після того, як ви зробите 
%     % посилання на нього у тексті, наприклад, див. роботи~\cite{ct1, ct2}.



% \chapconclude{\ref{chap:theory}}

%     % Наприкінці розділу знову наводяться коротенькі підсумки.